{"timestamp":"2025-07-01T23:27:13.503427","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-01T23:27:13.504098","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/basicDag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-01T23:27:13.800424","level":"info","event":"Starting docker container from image hello-world","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.109354","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.109928","level":"info","event":"Hello from Docker!","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110131","level":"info","event":"This message shows that your installation appears to be working correctly.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110285","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110513","level":"info","event":"To generate this message, Docker took the following steps:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110655","level":"info","event":" 1. The Docker client contacted the Docker daemon.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110731","level":"info","event":" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110801","level":"info","event":"    (amd64)","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110872","level":"info","event":" 3. The Docker daemon created a new container from that image which runs the","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.110963","level":"info","event":"    executable that produces the output you are currently reading.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111077","level":"info","event":" 4. The Docker daemon streamed that output to the Docker client, which sent it","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111147","level":"info","event":"    to your terminal.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111239","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111322","level":"info","event":"To try something more ambitious, you can run an Ubuntu container with:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111389","level":"info","event":" $ docker run -it ubuntu bash","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111453","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111517","level":"info","event":"Share images, automate workflows, and more with a free Docker ID:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.111926","level":"info","event":" https://hub.docker.com/","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.112068","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.112243","level":"info","event":"For more examples and ideas, visit:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.112427","level":"info","event":" https://docs.docker.com/get-started/","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.293536","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('0197c850-b6f1-75ca-a633-95b940d636b1'), task_id='tropo_job_group.spinup_workers', dag_id='time_based_demo_dag', run_id='manual__2025-07-01T23:26:59.708589+00:00', try_number=1, map_index=1, hostname='d6204bd8c1d5', context_carrier={}, task=<Task(DockerOperator): tropo_job_group.spinup_workers>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 7, 1, 23, 27, 13, 287308, tzinfo=TzInfo(UTC)), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task"}
