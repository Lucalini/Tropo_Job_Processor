{"timestamp":"2025-07-01T23:27:13.507343","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-01T23:27:13.507975","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/basicDag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-01T23:27:13.799437","level":"info","event":"Starting docker container from image hello-world","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.126694","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.127056","level":"info","event":"Hello from Docker!","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.127234","level":"info","event":"This message shows that your installation appears to be working correctly.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.127395","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.127554","level":"info","event":"To generate this message, Docker took the following steps:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.128052","level":"info","event":" 1. The Docker client contacted the Docker daemon.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.128314","level":"info","event":" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.128738","level":"info","event":"    (amd64)","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.128995","level":"info","event":" 3. The Docker daemon created a new container from that image which runs the","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.129166","level":"info","event":"    executable that produces the output you are currently reading.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.129350","level":"info","event":" 4. The Docker daemon streamed that output to the Docker client, which sent it","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.129615","level":"info","event":"    to your terminal.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.129789","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.129939","level":"info","event":"To try something more ambitious, you can run an Ubuntu container with:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130036","level":"info","event":" $ docker run -it ubuntu bash","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130166","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130280","level":"info","event":"Share images, automate workflows, and more with a free Docker ID:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130383","level":"info","event":" https://hub.docker.com/","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130459","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130524","level":"info","event":"For more examples and ideas, visit:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.130694","level":"info","event":" https://docs.docker.com/get-started/","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-07-01T23:27:14.313507","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('0197c850-ac90-738d-b881-05fe60ee2503'), task_id='tropo_job_group.spinup_workers', dag_id='time_based_demo_dag', run_id='manual__2025-07-01T23:26:59.708589+00:00', try_number=1, map_index=0, hostname='d6204bd8c1d5', context_carrier={}, task=<Task(DockerOperator): tropo_job_group.spinup_workers>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 7, 1, 23, 27, 13, 281781, tzinfo=TzInfo(UTC)), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task"}
